{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Dati del Circuito (circuits)\n",
    "country:\n",
    "\n",
    "Codifica one-hot per catturare pattern specifici (es. piloti bravi in circuiti stradali come Monaco).\n",
    "\n",
    "Coordinate geografiche (lat, lng, alt):\n",
    "\n",
    "Influenza su prestazioni (es. motori turbo a alta quota in Messico).\n",
    "\n",
    "B. Prestazioni Recenti (standings, constructor_standings)\n",
    "Punti e vittorie (points, wins):\n",
    "\n",
    "Media mobile ultime 5 gare per valutare la \"forma\" attuale.\n",
    "\n",
    "Posizione nel campionato (position in standings):\n",
    "\n",
    "Un pilota in top 3 potrebbe essere più aggressivo.\n",
    "\n",
    "C. Qualifiche (qualifying)\n",
    "Gap qualifica-gara (position vs grid):\n",
    "\n",
    "Se un pilota parte 5° ma in qualifica era 1°, potrebbe avere penalità (motore/gearbox).\n",
    "\n",
    "D. Affidabilità (results.statusId)\n",
    "Tasso di ritiro per pilota/team:\n",
    "\n",
    "Se un team ha il 30% di ritiri, riduci la previsione di posizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['constructorId'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     df \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_db()\u001b[38;5;241m.\u001b[39mtable_dict[table_name]\u001b[38;5;241m.\u001b[39mdf\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[columns] \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01melse\u001b[39;00m df\n\u001b[1;32m---> 21\u001b[0m drivers \u001b[38;5;241m=\u001b[39m \u001b[43msafe_get_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrivers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdriverId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstructorId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnationality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m results \u001b[38;5;241m=\u001b[39m safe_get_table(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresultId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraceId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdriverId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstructorId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatusId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastestLap\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m races \u001b[38;5;241m=\u001b[39m safe_get_table(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraces\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraceId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcircuitId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36msafe_get_table\u001b[1;34m(table_name, columns)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msafe_get_table\u001b[39m(table_name, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     18\u001b[0m     df \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_db()\u001b[38;5;241m.\u001b[39mtable_dict[table_name]\u001b[38;5;241m.\u001b[39mdf\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01melse\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['constructorId'] not in index\""
     ]
    }
   ],
   "source": [
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# 1. Caricamento dati completo\n",
    "dataset = get_dataset(name=\"rel-f1\", download=True)\n",
    "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
    "\n",
    "# Estrazione di TUTTE le tabelle necessarie\n",
    "def safe_get_table(table_name, columns=None):\n",
    "    df = dataset.get_db().table_dict[table_name].df\n",
    "    return df[columns] if columns else df\n",
    "\n",
    "drivers = safe_get_table('drivers', ['driverId', 'constructorId', 'dob', 'nationality'])\n",
    "results = safe_get_table('results', ['resultId', 'raceId', 'driverId', 'constructorId', 'grid', 'position', 'statusId', 'fastestLap', 'rank'])\n",
    "races = safe_get_table('races', ['raceId', 'circuitId', 'date', 'year', 'round'])\n",
    "qualifying = safe_get_table('qualifying', ['raceId', 'driverId', 'position'])\n",
    "standings = safe_get_table('standings', ['raceId', 'driverId', 'points', 'wins', 'position'])\n",
    "circuits = safe_get_table('circuits', ['circuitId', 'country', 'lat', 'lng', 'alt'])\n",
    "constructor_standings = safe_get_table('constructor_standings', ['raceId', 'constructorId', 'points', 'wins'])\n",
    "\n",
    "# 2. Feature Engineering Avanzato\n",
    "def create_enhanced_features(df):\n",
    "    # Merge a cascata con tutte le tabelle\n",
    "    merged = (\n",
    "        df.merge(results, on=['raceId', 'driverId'], how='left')\n",
    "          .merge(qualifying, on=['raceId', 'driverId'], how='left', suffixes=('', '_qual'))\n",
    "          .merge(standings, on=['raceId', 'driverId'], how='left', suffixes=('', '_stand'))\n",
    "          .merge(races, on='raceId', how='left')\n",
    "          .merge(circuits, on='circuitId', how='left')\n",
    "          .merge(drivers, on='driverId', how='left')\n",
    "          .merge(constructor_standings, on=['raceId', 'constructorId'], how='left', suffixes=('', '_const'))\n",
    "    )\n",
    "    \n",
    "    # Calcolo feature esistenti\n",
    "    merged['driver_avg'] = merged.groupby('driverId')['position'].transform('mean').fillna(20)\n",
    "    merged['circuit_avg'] = merged.groupby(['driverId', 'circuitId'])['position'].transform('mean').fillna(20)\n",
    "    merged['constructor_avg'] = merged.groupby('constructorId')['position'].transform('mean').fillna(20)\n",
    "    \n",
    "    # Nuove feature avanzate\n",
    "    merged['recent_points'] = merged.groupby('driverId')['points'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "    merged['qualifying_gap'] = (merged['grid'] - merged['position_qual']).fillna(0)\n",
    "    merged['reliability'] = merged.groupby('constructorId')['statusId'].transform(lambda x: (x == 1).mean()).fillna(0.9)  # 1 = Finished?\n",
    "    merged['age_at_race'] = (pd.to_datetime(merged['date']) - pd.to_datetime(merged['dob'])).dt.days / 365\n",
    "    merged['season_progress'] = merged['round'] / merged.groupby('year')['round'].transform('max')\n",
    "    \n",
    "    # Feature tecniche\n",
    "    merged['fast_lap_ability'] = (merged['rank'] == 1).astype(int).fillna(0)\n",
    "    merged['constructor_momentum'] = merged.groupby('constructorId')['points_const'].transform(lambda x: x.diff().rolling(3).mean()).fillna(0)\n",
    "    \n",
    "    # Selezione feature finali\n",
    "    features = merged[[\n",
    "        'driverId', 'constructorId', 'circuitId', 'grid',\n",
    "        'driver_avg', 'circuit_avg', 'constructor_avg',\n",
    "        'recent_points', 'qualifying_gap', 'reliability',\n",
    "        'age_at_race', 'season_progress', 'fast_lap_ability',\n",
    "        'constructor_momentum', 'country'\n",
    "    ]]\n",
    "    \n",
    "    return features, merged['position']\n",
    "\n",
    "# 3. Preparazione dati\n",
    "train_table = task.get_table(\"train\").df\n",
    "val_table = task.get_table(\"val\").df\n",
    "test_table = task.get_table(\"test\").df\n",
    "\n",
    "# Aggiungi date per calcoli temporali\n",
    "for table in [train_table, val_table, test_table]:\n",
    "    table['date'] = pd.to_datetime(table['date'])\n",
    "\n",
    "# Creazione dataset\n",
    "X_train, y_train = create_enhanced_features(train_table)\n",
    "X_val, y_val = create_enhanced_features(val_table)\n",
    "X_test, y_test = create_enhanced_features(test_table)\n",
    "\n",
    "# 4. Pipeline avanzata\n",
    "numeric_features = [\n",
    "    'grid', 'driver_avg', 'circuit_avg', 'constructor_avg',\n",
    "    'recent_points', 'qualifying_gap', 'reliability',\n",
    "    'age_at_race', 'season_progress', 'fast_lap_ability',\n",
    "    'constructor_momentum'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'driverId', 'constructorId', 'circuitId', 'country'\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "])\n",
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=15,\n",
    "        min_samples_leaf=3,\n",
    "        max_features=0.5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. Addestramento e valutazione\n",
    "print(\"\\nAddestramento modello avanzato...\")\n",
    "print(f\"Training samples: {len(X_train)}, Features: {len(numeric_features + categorical_features)}\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "val_pred = model.predict(X_val)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nRisultati avanzati:\")\n",
    "print(f\"Validation MAE: {mean_absolute_error(y_val, val_pred):.2f}\")\n",
    "print(f\"Test MAE: {mean_absolute_error(y_test, test_pred):.2f}\")\n",
    "\n",
    "# 6. Analisi feature importance (opzionale)\n",
    "if hasattr(model.steps[1][1], 'feature_importances_'):\n",
    "    feature_names = (\n",
    "        numeric_features + \n",
    "        list(model.named_steps['columntransformer'].named_transformers_['cat'].get_feature_names_out())\n",
    "    )\n",
    "    print(\"\\nTop 10 feature importanti:\")\n",
    "    for name, score in sorted(zip(feature_names, model.steps[1][1].feature_importances_), \n",
    "                             key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"{name}: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
